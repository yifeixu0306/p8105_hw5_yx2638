p8105_hw5_yx2638
================
Yifei Xu
2022-11-10

### Problem 2

First, we read the data from the GitHub repository.

``` r
data_url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide = read_csv(url(data_url)) 
```

The raw dataset collects data on homicides in 50 large U.S. cities. It
has 52179 observations of homicides and 12 key variables represent uid,
reported date, victims’ last name, first name, race, age, sex, city,
state, latitude, longitude, and disposition.

Next, we create a city_state variable and a resolved variable to
indicate whether the homicides were solved. There was one observation
was mis-recorded as “Tulsa, AL” and we plan to drop it since Tulsa is
the city in the state of Oklahoma rather than Alabama.

``` r
homicide_tidy = homicide %>%
  mutate(city_state = str_c(city, state, sep = ", "),
         resolved= case_when(disposition == "Closed by arrest" ~ "solved",
                                disposition == "Closed without arrest" ~ "unsolved",
                                disposition == "Open/No arrest" ~ "unsolved")) %>% 
  select(city_state, everything()) %>%
  filter(city_state != "Tulsa, AL")
```

Then summarize within cities to obtain the total number of homicides and
the number of unsolved homicides.

``` r
city_summary = homicide_tidy %>%
  group_by(city_state) %>%
  summarise(num_homicides = n(),
            num_unsolved_homicides = sum(resolved == "unsolved")) 

city_summary 
```

    ## # A tibble: 50 × 3
    ##    city_state      num_homicides num_unsolved_homicides
    ##    <chr>                   <int>                  <int>
    ##  1 Albuquerque, NM           378                    146
    ##  2 Atlanta, GA               973                    373
    ##  3 Baltimore, MD            2827                   1825
    ##  4 Baton Rouge, LA           424                    196
    ##  5 Birmingham, AL            800                    347
    ##  6 Boston, MA                614                    310
    ##  7 Buffalo, NY               521                    319
    ##  8 Charlotte, NC             687                    206
    ##  9 Chicago, IL              5535                   4073
    ## 10 Cincinnati, OH            694                    309
    ## # … with 40 more rows

Below is the estimation of the proportion of homicides that are unsolved
in Baltimore, MD.

``` r
bal_homicide = homicide_tidy %>%
  filter(city_state == "Baltimore, MD")

bal_summary = bal_homicide %>%
  group_by(city_state) %>%
  summarise(num_homicides = n(),
            num_unsolved_homicides = sum(resolved == "unsolved"),
            prop_unsolved_homicides = num_unsolved_homicides/num_homicides) 

bal_test = prop.test(x = bal_summary %>% pull(num_unsolved_homicides),
                     n = bal_summary %>% pull(num_homicides))

bal_test %>% broom::tidy()
```

    ## # A tibble: 1 × 8
    ##   estimate statistic  p.value parameter conf.low conf.high method        alter…¹
    ##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>         <chr>  
    ## 1    0.646      239. 6.46e-54         1    0.628     0.663 1-sample pro… two.si…
    ## # … with abbreviated variable name ¹​alternative

``` r
# the estimated proportion
est_prop = bal_test %>% broom::tidy() %>%
  pull(estimate) %>%
  round(digit = 3)

# the confidence interval
conf_low = bal_test %>% broom::tidy() %>%
  pull(conf.low) %>%
  round(digit = 3)

conf_high = bal_test %>% broom::tidy() %>%
  pull(conf.high) %>%
  round(digit = 3)
```

The estimate proportion of unsolved homicides in Baltimore, MD is 0.646
and the confidence interval is \[0.628, 0.663\].

We will run proportion test for each of the cities in the dataset.

``` r
results_df = 
  city_summary %>% 
  mutate(prop_test = map2(.x = num_unsolved_homicides, .y = num_homicides, ~prop.test(x = .x, n = .y)),
         tidy_test = map(.x = prop_test, ~broom::tidy(.x))) %>% 
  select(city_state, tidy_test) %>% 
  unnest(tidy_test) %>% 
  select(city_state, estimate, conf.low, conf.high)

results_df
```

    ## # A tibble: 50 × 4
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    0.386    0.337     0.438
    ##  2 Atlanta, GA        0.383    0.353     0.415
    ##  3 Baltimore, MD      0.646    0.628     0.663
    ##  4 Baton Rouge, LA    0.462    0.414     0.511
    ##  5 Birmingham, AL     0.434    0.399     0.469
    ##  6 Boston, MA         0.505    0.465     0.545
    ##  7 Buffalo, NY        0.612    0.569     0.654
    ##  8 Charlotte, NC      0.300    0.266     0.336
    ##  9 Chicago, IL        0.736    0.724     0.747
    ## 10 Cincinnati, OH     0.445    0.408     0.483
    ## # … with 40 more rows

Below is a plot that shows the estimates and CIs for each city.

``` r
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(x = "City",
       y = "Estimate",
       title = "Estimates and Confidence Intervals of Porportion of Unsolved Homicides for Each City") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

![](p8105_hw5_yx2638_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

### Problem 3

First create the function to generate normally distributed data and
conduct t-test.

``` r
set.seed(1)

sim_t_test = function(n = 30, mu, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
    ) 
    
  test_data = t.test(sim_data, mu = 0, conf.level = 0.95)
  
  sim_data %>% 
    summarize(
      mu_hat =pull(broom::tidy(test_data), estimate),
      p_val = pull(broom::tidy(test_data), p.value)
    )
}
```

Then generate 5000 datasets from the model $x \sim Normal[\mu, \sigma]$
and repeat t-test

``` r
sim_results_df = 
  tibble(true_mean = c(0:6)) %>% 
  mutate(
    output_lists = map(.x = true_mean, ~rerun(5000, sim_t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

Below is a plot showing the proportion of times the null was rejected
(the power of the test) on the $y$ axis and the true value of $\mu$ on
the $x$ axis.

``` r
sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    count = n(),
    rej_num = sum(p_val < 0.05),
    rej_prop = rej_num/count
  ) %>%
  ggplot(aes(x = true_mean, y = rej_prop)) +
  geom_point() +
  geom_line() + 
  scale_x_continuous(n.breaks = 10) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Relationship Between Effect Size and Power",
    x = "True Mean",
    y = "Power of Test"
  )
```

![](p8105_hw5_yx2638_files/figure-gfm/unnamed-chunk-9-1.png)<!-- -->

Next is a plot showing the average estimate of $\mu$ on the $y$ axis and
the true value of $\mu$ on the $x$ axis.

``` r
sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat = mean(mu_hat)
  ) %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat)) +
  geom_point() +
  geom_line() + 
  scale_x_continuous(n.breaks = 6) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Association Between True Mean and Average Estimate of Mean",
    x = "True Mean",
    y = "Average Estimate of Mean"
  )
```

![](p8105_hw5_yx2638_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

We then overlay a second plot on the first to show the average estimate
of $\mu$ only in samples for which the null was rejected on the $y$ axis
and the true value of $\mu$ on the $x$ axis.

``` r
overall_df = sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat = mean(mu_hat)
  ) 

sim_results_df %>%
  filter(p_val < 0.05) %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat_rej = mean(mu_hat)
  ) %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat_rej, color = "Rejected samples")) +
  geom_point() +
  geom_line() + 
  geom_point(data = overall_df, aes(x = true_mean, y = avg_mu_hat, color = "All samples")) +
  geom_line(data = overall_df, aes(x = true_mean, y = avg_mu_hat, color = "All samples")) +  
  scale_x_continuous(n.breaks = 6) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Association Between True Mean and Average Estimate of Mean",
    x = "True Mean",
    y = "Average Estimate of Mean",
    color = "Type"
  )
```

![](p8105_hw5_yx2638_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->
