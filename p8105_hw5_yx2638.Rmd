---
title: "p8105_hw5_yx2638"
author: "Yifei Xu"
date: "2022-11-10"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
library(janitor)
library(readr)
library(rvest)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


### Problem 2

First, we read the data from the GitHub repository. 
```{r, message=FALSE}
data_url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide = read_csv(url(data_url)) 
```
The raw dataset collects data on homicides in 50 large U.S. cities. It has `r nrow(homicide)` observations of homicides and `r ncol(homicide)` key variables represent uid, reported date, victims' last name, first name, race, age, sex, city, state, latitude, longitude, and disposition.


Next, we create a city_state variable and a resolved variable to indicate whether the homicides were solved. There was one observation was mis-recorded as "Tulsa, AL" and we plan to drop it since Tulsa is the city in the state of Oklahoma rather than Alabama.
```{r}
homicide_tidy = homicide %>%
  mutate(city_state = str_c(city, state, sep = ", "),
         resolved= case_when(disposition == "Closed by arrest" ~ "solved",
                                disposition == "Closed without arrest" ~ "unsolved",
                                disposition == "Open/No arrest" ~ "unsolved")) %>% 
  select(city_state, everything()) %>%
  filter(city_state != "Tulsa, AL")
  
```

Then summarize within cities to obtain the total number of homicides and the number of unsolved homicides.
```{r}
city_summary = homicide_tidy %>%
  group_by(city_state) %>%
  summarise(num_homicides = n(),
            num_unsolved_homicides = sum(resolved == "unsolved")) 

city_summary 
```

Below is the estimation of the proportion of homicides that are unsolved in Baltimore, MD.
```{r}
bal_homicide = homicide_tidy %>%
  filter(city_state == "Baltimore, MD")

bal_summary = bal_homicide %>%
  group_by(city_state) %>%
  summarise(num_homicides = n(),
            num_unsolved_homicides = sum(resolved == "unsolved"),
            prop_unsolved_homicides = num_unsolved_homicides/num_homicides) 

bal_test = prop.test(x = bal_summary %>% pull(num_unsolved_homicides),
                     n = bal_summary %>% pull(num_homicides))

bal_test %>% broom::tidy()

# the estimated proportion
est_prop = bal_test %>% broom::tidy() %>%
  pull(estimate) %>%
  round(digit = 3)

# the confidence interval
conf_low = bal_test %>% broom::tidy() %>%
  pull(conf.low) %>%
  round(digit = 3)

conf_high = bal_test %>% broom::tidy() %>%
  pull(conf.high) %>%
  round(digit = 3)

```

The estimate proportion of unsolved homicides in Baltimore, MD is `r est_prop` and the confidence interval is `r paste("[", conf_low, ", ", conf_high, "]", sep ="")`.


We will run proportion test for each of the cities in the dataset.
```{r, warning=FALSE, message=FALSE}
results_df = 
  city_summary %>% 
  mutate(prop_test = map2(.x = num_unsolved_homicides, .y = num_homicides, ~prop.test(x = .x, n = .y)),
         tidy_test = map(.x = prop_test, ~broom::tidy(.x))) %>% 
  select(city_state, tidy_test) %>% 
  unnest(tidy_test) %>% 
  select(city_state, estimate, conf.low, conf.high)

results_df
```

Below is a plot that shows the estimates and CIs for each city.
```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(x = "City",
       y = "Estimate",
       title = "Estimates and Confidence Intervals of Porportion of Unsolved Homicides for Each City") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


### Problem 3

First create the function to generate normally distributed data and conduct t-test.
```{r}
set.seed(1)

sim_t_test = function(n = 30, mu, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
    ) 
    
  test_data = t.test(sim_data, mu = 0, conf.level = 0.95)
  
  sim_data %>% 
    summarize(
      mu_hat =pull(broom::tidy(test_data), estimate),
      p_val = pull(broom::tidy(test_data), p.value)
    )
}

```

Then generate 5000 datasets from the model $x \sim Normal[\mu, \sigma]$ and repeat t-test 
```{r}
sim_results_df = 
  tibble(true_mean = c(0:6)) %>% 
  mutate(
    output_lists = map(.x = true_mean, ~rerun(5000, sim_t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)
```

Below is a plot showing the proportion of times the null was rejected (the power of the test) on the $y$ axis and the true value of $\mu$ on the $x$ axis.
```{r}
sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    count = n(),
    rej_num = sum(p_val < 0.05),
    rej_prop = rej_num/count
  ) %>%
  ggplot(aes(x = true_mean, y = rej_prop)) +
  geom_point() +
  geom_line() + 
  scale_x_continuous(n.breaks = 10) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Relationship Between Effect Size and Power",
    x = "True Mean",
    y = "Power of Test"
  )

```

Next is a plot showing the average estimate of $\mu$ on the $y$ axis and the true value of $\mu$ on the $x$ axis.
```{r}
sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat = mean(mu_hat)
  ) %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat)) +
  geom_point() +
  geom_line() + 
  scale_x_continuous(n.breaks = 6) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Association Between True Mean and Average Estimate of Mean",
    x = "True Mean",
    y = "Average Estimate of Mean"
  )

```

We then overlay a second plot on the first to show the average estimate of $\mu$ only in samples for which the null was rejected on the $y$ axis and the true value of $\mu$ on the $x$ axis.
```{r}
overall_df = sim_results_df %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat = mean(mu_hat)
  ) 

sim_results_df %>%
  filter(p_val < 0.05) %>%
  group_by(true_mean) %>%
  summarise(
    avg_mu_hat_rej = mean(mu_hat)
  ) %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat_rej, color = "Rejected samples")) +
  geom_point() +
  geom_line() + 
  geom_point(data = overall_df, aes(x = true_mean, y = avg_mu_hat, color = "All samples")) +
  geom_line(data = overall_df, aes(x = true_mean, y = avg_mu_hat, color = "All samples")) +  
  scale_x_continuous(n.breaks = 6) +
  scale_y_continuous(n.breaks = 6) +
  labs(
    title = "Association Between True Mean and Average Estimate of Mean",
    x = "True Mean",
    y = "Average Estimate of Mean",
    color = "Type"
  )

```












